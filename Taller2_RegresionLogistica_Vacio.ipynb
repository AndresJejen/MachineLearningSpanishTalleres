{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtXzXdO51N36"
   },
   "source": [
    "# Regresión logística con una perspectiva de Redes Neuronales\n",
    "\n",
    "En este ejercicio construirá un clasificador de regresión logística. En este cuaderno encontrará la guía para hacerlo desde una perspectiva de redes neuronales, ganando una intuición sobre lo que es el aprendizaje computacional y el deep learning.\n",
    "\n",
    "**Instrucciones:**\n",
    "- No utilize bucles-for/while en su código, a menos que se le pida hacerlo explícitamente.\n",
    "\n",
    "**Tras este taller usted va a ser capaz de:**\n",
    "- Construir la arquitectura general de un algoritmo de aprendizaje, incluyendo:\n",
    "    - Inicialización de parámetros\n",
    "    - Calcular la función de coste y su gradiente\n",
    "    - Utilizar un algoritmo de optimización (descenso en la dirección del gradiente, GD) \n",
    "- Reunir todas las tres funciones en un modelo principal en el orden adecuado.\n",
    "\n",
    "Manos a la obra!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlmeO63m1N37"
   },
   "source": [
    "## 1 - Paquetes ##\n",
    "\n",
    "Primero, importamos los paquetes que vamos a necesitar a lo largo de este taller. \n",
    "- [numpy](www.numpy.org) paquete básico para ciencias computacionales con Python.\n",
    "- [h5py](http://www.h5py.org) paquete para interactuar con un conjunto de datos guardado en un archivo de tipo H5.\n",
    "- [matplotlib](http://matplotlib.org) librería para graficar en Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) y [scipy](https://www.scipy.org/) usados para probar el modelo con sus propias imagenes al final del taller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3Q1ECN51N39"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-L6xnoi1N4C"
   },
   "source": [
    "## 2 - Enunciado del problema ##\n",
    "\n",
    "**Enunciado**: El siguiente conjunto de datos está disponible (\"data.h5\") con la siguiente información:\n",
    "    - un conjunto de entrenamiento m_train con imagenes etiquetadas como gato (y=1) o no-gato (y=0)\n",
    "    - un conjunto de prueba m_test con imagenes etiquetadas como cat/gato o non-cat/no-gato\n",
    "    - cada imagen tiene dimensiones (num_px, num_px, 3) donde 3 es para los canales RGB (nótese que cada imagen es cuadrada (altura = num_px) y (ancho = num_px).\n",
    "\n",
    "Usted debe construir un algoritmo simple de reconocimiento de imagenes que pueda clasificar correctamente las imagenes como gato o no-gato.\n",
    "\n",
    "Primero, examinemos los datos. Cargue el archivo con el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eniIfuR1N4E"
   },
   "outputs": [],
   "source": [
    "# Carga de datos (gato/no-gato)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "clases=[\"no-gato\", \"gato\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLl5ayGl1N4H"
   },
   "source": [
    "Comprobamos las dimensiones de una observación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCwXNTdU1N4H",
    "outputId": "93b942bf-6eeb-44ef-c956-ce87180f1a9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_orig[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHHeSSEA1N4O"
   },
   "source": [
    "Añadimos \"_orig\" al final de los datos de entrenamiento y prueba porque vamos a pre-procesarlos. Luego de esto, vamos a obtener un train_set_x y un test_set_x (nótese que las etiquetas de train_set_y y test_set_y no necesitan ningún pre-procesamiento).\n",
    "\n",
    "Cada observación (línea) del train_set_x_orig y del test_set_x_orig es un arreglo representando una imagen. Se puede visualizar cada observación mediante el siguiente código. Puede cambiar el valor del `indice` para visualizar imagenes distintas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvzyeDep1N4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen #0, es un 'no-gato'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de una imagen\n",
    "indice = 0\n",
    "plt.imshow(train_set_x_orig[indice])\n",
    "print (\"La imagen #\" + str(indice) + \", es un '\" + str(clases[np.squeeze(train_set_y[:, indice])]) + \"'\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYg47rFi1N4T"
   },
   "source": [
    "Muchos fallos/bugs del código en deep learning ocurren por tener dimensiones de la matriz/vector que no encajan. Si puede mantener las dimensiones correctas podrá evitar tener que dedicar tiempo a corregir estos fallos. \n",
    "\n",
    "**Ejercicio:** Encuentre los valores para:\n",
    "    - m_train (número de ejemplos de entrenamiento)\n",
    "    - m_test (número de ejemplos de prueba)\n",
    "    - num_px (= altura = ancho de la imagen)\n",
    "Recuerde que `train_set_x_orig` es un arreglo numpy de dimensiones (m_train, num_px, num_px, 3). De esta manera, puede acceder a `m_train` escribiendo `train_set_x_orig.shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clJpaVYl1N4U",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 3 líneas de código)\n",
    "m_train = \n",
    "m_test =\n",
    "num_px = \n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print (\"Número de ejemplos de entrenamiento: m_train = \" + str(m_train))\n",
    "print (\"Número de ejemplos de prueba: m_test = \" + str(m_test))\n",
    "print (\"Altura/Ancho de cada imagen: num_px = \" + str(num_px))\n",
    "\n",
    "print (\"Cada imagen es de tamaño: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"Dimensión del train_set_x: \" + str(train_set_x_orig.shape))\n",
    "print (\"Dimensión del train_set_y: \" + str(train_set_y.shape))\n",
    "print (\"Dimensión del test_set_x: \" + str(test_set_x_orig.shape))\n",
    "print (\"Dimensión del test_set_y: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE9P8s5n1N4X"
   },
   "source": [
    "**Salida esperada para m_train, m_test y num_px**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**m_train**</td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**m_test**</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**num_px**</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1lg-zi01N4Y"
   },
   "source": [
    "Es recomendable ahora re-dimensionar las imagenes de tamaño (num_px, num_px, 3) en un arreglo numpy de dimensión (num_px $*$ num_px $*$ 3, 1). Luego, los conjuntos de entrenamiento y prueba serán un arreglo numpy donde cada columna representa una imagen (aplanada). Deberían haber m_train y m_test columnas.\n",
    "\n",
    "**Ejercicio:** Re-dimensione los conjuntos de datos de entrenamiento y prueba para que las imagenes de tamaño (num_px, num_px, 3) sean aplanadas en vectores de dimensión (num\\_px $*$ num\\_px $*$ 3, 1).\n",
    "\n",
    "Ayuda. Cuando se quiere aplanar una matriz X de dimensión (a,b,c,d) en una matriz X_flatten de dimensión (b$*$c$*$d, a) se puede usar: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T es la transpuesta de X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4FH1kU91N4Z"
   },
   "outputs": [],
   "source": [
    "# Re-dimensione los ejemplos de entrenamiento y prueba\n",
    "\n",
    "### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "train_set_x_flatten = \n",
    "test_set_x_flatten = \n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print (\"Dimensión del train_set_x_flatten: \" + str(train_set_x_flatten.shape))\n",
    "print (\"Dimensión del train_set_y: \" + str(train_set_y.shape))\n",
    "print (\"Dimensión del test_set_x_flatten: \" + str(test_set_x_flatten.shape))\n",
    "print (\"Dimensión del test_set_y: \" + str(test_set_y.shape))\n",
    "print (\"Chequeo luego del re-dimensionamiento: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZl88Ftp1N4e"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:55%\">\n",
    "  <tr>\n",
    "    <td>**Dimensión train_set_x_flatten**</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**Dimensión train_set_y**</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**Dimensión test_set_x_flatten**</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**Dimensión test_set_y**</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>**Chequeo tras el re-dimensionamiento**</td>\n",
    "  <td>[17 31 56 22 33]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLsILF5v1N4f"
   },
   "source": [
    "Las imagenes a color son comúnmente representadas mediante los tres canales rojo, verde y azul (RGB) para cada pixel, de tal manera que a cada pixel le corresponde un vector de tres números en el rango de 0 a 255.\n",
    "\n",
    "Un paso muy común en el pre-procesamiento de datos en machine learning es el de estandarizar el conjunto de datos multivariado, es decir, restando la media de cada vector a cada ejemplo, y dividiendo por la desviación estandar del vector. En este caso del tratamiento de imagenes, es más simple y conveniente tan solo dividir todas las filas del conjunto de datos por 255 (el valor máximo de un canal RGB).\n",
    "\n",
    "<!-- Durante el entrenamiento del modelo, se multiplican pesos y se suman sesgos a algunos inputs iniciales para observar activaciones neuronales. Luego se retro-propaga a partir de los gradientes para entrenar el modelo. Pero es importante que cada patrón del input tenga un rango similar para que los gradientes no exploten. Más adelante se profundizará en esto. !--> \n",
    "\n",
    "Normalizemos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZzwIVuG1N4h"
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7OU-rnH1N4l"
   },
   "source": [
    "<font color='blue'>\n",
    "**Recapitulemos:**\n",
    "\n",
    "Pasos comunes para el pre-procesamiento de un nuevo conjunto de datos:\n",
    "- Examinar las dimensiones del problema (m_train, m_test, num_px, ...)\n",
    "- Re-dimensionar los conjuntos de datos para que cada ejemplo sea un vector de tamaño (num_px \\* num_px \\* 3, 1)\n",
    "- Normalizar o estandarizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otzr673_1N4o"
   },
   "source": [
    "## 3 - Arquitectura general de un algoritmo de aprendizaje ##\n",
    "\n",
    "Llegó el momento de diseñar un algoritmo simple para distinguir imagenes de gatos y de aquello que no son gatos.\n",
    "\n",
    "Debe constuir un modelos de regresión logística, desde una perspectiva de Redes Neuronales.\n",
    "\n",
    "**Formulación del algoritmo**:\n",
    "\n",
    "Para un ejemplo $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoide(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "El coste se calcula sumando sobre todos los ejemplos de entrenamiento:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Paso a paso**:\n",
    "En este ejercicio, se deben dar los siguientes pasos: \n",
    "    - Inicializar los parámetros del modelo\n",
    "    - Aprender los parámetros del modelo a partir de la minimización del coste  \n",
    "    - Utilizar los parámetros aprendidos para hacer predicciones (sobr el conjunto de prueba)\n",
    "    - Analizar los resultados y concluir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJThnylV1N4p"
   },
   "source": [
    "## 4 - Construyendo las partes del algoritmo ## \n",
    "\n",
    "Los pasos principales para construir una red neuronal son: \n",
    "1. Definir la estructura del modelo (tal como el número de patrones en el input) \n",
    "2. Inicializar los parámetros del modelo\n",
    "3. Bucle:\n",
    "    - Calcular la pérdida actual (propagación hacia delante)\n",
    "    - Calcular el gradiente actual (retro-propagación)\n",
    "    - Actualizar los parámetros (descenso en la dirección del gradiente)\n",
    "\n",
    "Se suele construir 1-3 de manera separada e integrarlos en una función que llamaremos `model()`.\n",
    "\n",
    "### 4.1 - Funciones de ayuda\n",
    "\n",
    "**Ejercicio**: Utilizando su código del Taller_1 \"IntroPython_numpy\", implemente `sigmoid()`. Como se puede ver en la figura arriba, se debe computar $sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ para predecir. Para ello puede utilizar np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jv9vZTMo1N4q"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcule el sigmoide de z\n",
    "    Input:\n",
    "    z: Un escalar o arreglo numpy de cualquier tamaño\n",
    "    Output:\n",
    "    s: sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###  (≈ 1 línea de código)\n",
    "    s = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yc_QFhz_1N4u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"sigmoide([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1B8FIszR1N4z"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>**sigmoid([0, 2])**</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BwOuoF51N40"
   },
   "source": [
    "### 4.2 - Inicialización de parámteros\n",
    "\n",
    "**Ejercicio:** Implemente la inicialización de parámetros. Se tiene un vector w de ceros. Si no sabe qué función de numpy puede utilizar, puede buscar np.zeros() en la documentación de la biblioteca Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4La8ikN1N41"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Esta función crea un vector de ceros de dimensión (dim, 1) para w e inicializa b a 0.\n",
    "    Input:\n",
    "    dim: tamaño del vector w (número de parámetros para este caso)\n",
    "    Output:\n",
    "    w: vector inicializado de tamaño (dim, 1)\n",
    "    b: escalar inicializado (corresponde con el sesgo)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    w =    \n",
    "    b = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgvQpn_C1N45"
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30Bbhadd1N48"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "\n",
    "<table style=\"width:25%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** b **  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Para inputs de imagen, w será de tamaño (num_px $\\times$ num_px $\\times$ 3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfMNPGtF1N49"
   },
   "source": [
    "### 4.3 - Propagación hacia delante y hacia atrás\n",
    "\n",
    "Una vez los parámetros están inicializados, se pueden implementar los pasos de propagación hacia \"delante\" y hacia \"atrás\" para el aprendizaje de los parámetros.\n",
    "\n",
    "**Ejercicio:** Implemente la función `propagate()` que calcula la función de coste y su gradiente.\n",
    "\n",
    "**Ayuda**:\n",
    "\n",
    "Propagación hacia delante:\n",
    "- Se tiene X\n",
    "- Se calcula $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- Se calcula la función de coste/pérdida: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Se pueden usar las siguientes fórmulas: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9GBbvhO1N4_"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implemente la función de coste y su gradiente para la propagación\n",
    "    Input:\n",
    "    w: pesos, un arreglo numpy de tamaño (num_px * num_px * 3, 1)\n",
    "    b: sesgo, un escalar\n",
    "    X: datos de tamaño (num_px * num_px * 3, número de ejemplos)\n",
    "    Y: vector de etiquetas observadas (0 si es no-gato, 1 si es gato) de tamaño (1, número de ejemplos)\n",
    "    Output:\n",
    "    coste: coste negativo de log-verosimilitud para la regresión logística\n",
    "    dw: gradiente de la pérdida con respecto a w, con las mismas dimensiones que w\n",
    "    db: gradiente de la pérdida con respecto a b, con las mismas dimensiones que b\n",
    "    \n",
    "    (Sugerencia: escriba su código paso a paso para la propagación. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # PROPAGACIÓN HACIA DELANTE \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    A =                                                      # compute la activación\n",
    "    cost =                                                   # compute el coste\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # RETRO-PROPAGACIÓN (PROPAGACIÓN HACIA ATRÁS)\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    dw = \n",
    "    db = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPjtxhC81N5C"
   },
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"coste = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3jlQGzh1N5H"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j767c6t81N5H"
   },
   "source": [
    "### 4.4 - Optimización\n",
    "- Se tienen los parámetros inicializados.\n",
    "- También se tiene el código para calcular la función de coste y su gradiente.\n",
    "- Ahora se quieren actualizar los parámetros utilizando el descenso en la dirección del gradiente (GD).\n",
    "\n",
    "**Ejercicio:** Escriba la función de optimización. EL objetivo es el de aprender $w$ y $b$ minimizando la función de coste $J$. Para un parámetro $\\theta$, la regla de actualización es $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, donde $\\alpha$ es la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKzxdXA41N5J"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    Esta función optimiza w y b implementando el algoritmo de GD\n",
    "    Input:\n",
    "    w: pesos, un arreglo numpy de tamaño (num_px * num_px * 3, 1)\n",
    "    b: sesgo, un escalar\n",
    "    X: datos de tamaño (num_px * num_px * 3, número de ejemplos)\n",
    "    Y: vector de etiquetas observadas (0 si es no-gato, 1 si es gato) de tamaño (1, número de ejemplos)\n",
    "    num_iterations: número de iteracionespara el bucle de optimización\n",
    "    learning_rate: tasa de aprendizaje para la regla de actualización del GD\n",
    "    print_cost: True para imprimir la pérdida cada 100 iteraciones\n",
    "    Output:\n",
    "    params: diccionario con los pesos w y el sesgo b\n",
    "    grads: diccionario con los gradientes de los pesos y el sesgo con respecto a la función de pérdida\n",
    "    costs: lista de todos los costes calculados durante la optimización, usados para graficar la curva de aprendizaje.\n",
    "    \n",
    "    Sugerencia: puede escribir dos pasos e iterar sobre ellos:\n",
    "        1) Calcule el coste y el gradiente de los parámetros actuales. Use propagate().\n",
    "        2) Actualize los parámetros usando la regla del GD para w y b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Computación del coste y el gradiente (≈ 1-4 líneas de código)\n",
    "        ### EMPIEZE EL CÓDIGO AQUÍ ### \n",
    "        grads, cost = \n",
    "        ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "        \n",
    "        # Recupere las derivadas de grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Actualize la regla (≈ 2 líneas de código)\n",
    "        ### EMPIEZE EL CÓDIGO AQUÍ ###\n",
    "        w = \n",
    "        b = \n",
    "        ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "        \n",
    "        # Guarde los costes\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Se muestra el coste cada 100 iteraciones de entrenamiento\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Coste tras la iteración %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uvXlS9X1N5P"
   },
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJ8k89Wm1N5S"
   },
   "source": [
    "**Salida esperada**:  \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.19033591]\n",
    " [ 0.12259159]] </td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.92535983008 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.67752042]\n",
    " [ 1.41625495]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.219194504541 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4CwLUOI1N5U"
   },
   "source": [
    "**Ejercicio:** La función anterior aprende los parámetros w y b, que se pueden usar para predecir las etiquetas para el conjunto de datos X. Ahora implemente la función `predict()`. Hay dos pasos para calcular las predicciones:\n",
    "\n",
    "1. Calcule $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convierta a 0 las entradas de a (si la activación es <= 0.5) o 1 (si la activación es > 0.5), guarde las predicciones en un vector `Y_prediction`. Si lo desea, puede usar un `if`/`else` en un bucle `for`, aunque también hay una manera de vectorizarlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FwD0mqK1N5U"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Prediga si una etiqueta es 0 o 1 usando los parámetros de regresión logística aprendidos (w, b)\n",
    "    Input:\n",
    "    w: pesos, un arreglo numpy de tamaño (num_px * num_px * 3, 1)\n",
    "    b: sesgo, un escalar\n",
    "    X: datos de tamaño (num_px * num_px * 3, número de ejemplos)\n",
    "    Output:\n",
    "    Y_prediction: vector con todas las predicciones (0/1) para los ejemplos en X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute el vector \"A\" prediciendo las probabilidades de que la imagen contenga un gato\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "    A = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convierta las probabilidades A[0,i] a predicciones p[0,i]\n",
    "        ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1-4 líneas de código)\n",
    "        Y_prediction[0,i] =\n",
    "        ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-12ecae1N5X"
   },
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predicciones = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKMpRH6C1N5a"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             **predicciones**\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.  0.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQJjfPpb1N5a"
   },
   "source": [
    "<font color='blue'>\n",
    "**Recapitulemos:**\n",
    "Se han implementado varias funciones:\n",
    "- Inicialización de (w,b)\n",
    "- Optimización iterativa de la pérdida para aprender los parametros (w,b):\n",
    "    - computando el coste y su gradiente \n",
    "    - actualizando los parametros usando el GD\n",
    "- Se utilizan los parámetros aprendidos (w,b) para predecir las etiquetas para un conjunto dado de ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1DcQgoq1N5c"
   },
   "source": [
    "## 5 - Fusione todas las funciones ##\n",
    "\n",
    "Ahora debe construir el modelo global, estructurando todos los bloques que ha programado arriba.\n",
    "\n",
    "**Ejercicio:** Implemente la función madre. Use la siguiente notación:\n",
    "    - Y_prediction_test para las predicciones sobr el conjunto de prueba\n",
    "    - Y_prediction_train para las predicciones sobre el conjunto de entrenamiento\n",
    "    - w, costs, grads para las salidas de optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lz5G93JH1N5c"
   },
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Construye el modelo de regresión logística llamando las funciones implementadas anteriormente\n",
    "    Input:\n",
    "    X_train: conjunto de entrenamiento con dimensiones (num_px * num_px * 3, m_train)\n",
    "    Y_train: vector con las etiquetas de entrenamiento con dimensiones (1, m_train)\n",
    "    X_test: conjunto de prueba con dimensiones (num_px * num_px * 3, m_test)\n",
    "    Y_test: vector con las etiquetas de prueba con dimensiones (1, m_test)\n",
    "    num_iterations: (hiper-parámetro) número de iteracionespara para optimizar los parámetros\n",
    "    learning_rate: (hiper-parámetro) tasa de aprendizaje para la regla de optimize()\n",
    "    print_cost: True para imprimir la pérdida cada 100 iteraciones\n",
    "    Output:\n",
    "    d: diccionario con la información sobre el modelo.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Inicialize los parametros con ceros (≈ 1 línea de código)\n",
    "    w, b = \n",
    "\n",
    "    # Descenso en la dirección del gradiente (GD) (≈ 1 línea de código)\n",
    "    parameters, grads, costs = \n",
    "    \n",
    "    # Recupere los parámetros w y b del diccionario \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Prediga los ejemplos de prueba y entrenamiento (≈ 2 líneas de código)\n",
    "    Y_prediction_test = \n",
    "    Y_prediction_train = \n",
    "\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "    # Imprima los errores de entrenamiento y prueba\n",
    "    print(\"Precisión de entrenamiento: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"Precisión de prueba: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"Costes\": costs,\n",
    "         \"Prediccion_prueba\": Y_prediction_test, \n",
    "         \"Prediccion_entrenamiento\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"Tasa de aprendizaje\" : learning_rate,\n",
    "         \"Num_iteraciones\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EUsfa3ua1N5f"
   },
   "source": [
    "Run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CIeIsE51N5j"
   },
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qt_8BYr81N5n"
   },
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:50%\"> \n",
    "\n",
    "    <tr>\n",
    "        <td> **Coste tras la iteración 0 **  </td> \n",
    "        <td> 0.693147 </td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td> **Precisión de entrenamiento**  </td> \n",
    "        <td> 99.04306220095694 % </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>**Precisión de prueba** </td> \n",
    "        <td> 70.0 % </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cueFINup1N5o"
   },
   "source": [
    "**Nota**: La precisión de entrenamiento es cercana al 100%. Esto es una buena señal de que el modelo está aprendiendo, ya que muestra capacidad suficiente para ajustarse a los datos de entrenamiento. Por el otro lado, el error de prueba es del 70%. Este resultado no está mal tomando en cuenta que es un modelo bastante simple, dado el conjunto de datos que se ha usado, el cual es relativamente pequeño, y que el modelo de regresión logística es un calsificador lineal. La próxima semana veremos un clasificador más complejo, y que permitirá obtener mejores resultados. \n",
    "\n",
    "Nótese también que el modelo se está sobre-ajustando a los datos de entrenamiento. Más adelante veremos cómo se peude reducir este sobre-ajuste (\"overfitting\"), por ejemplo mediante regularización. A continuación puede examinar las predicciones de las imagenes de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JQ37FQX1N5p"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de una imagen mal clasificada.\n",
    "index = 6\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "clase=clases[int(d[\"Prediccion_prueba\"][0,index])]\n",
    "print (\"Para y = \" + str(test_set_y[0,index]) + \", el modelo dice que es una imagen de un \\\"\" + clase +  \"\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFVdaS-m1N5s"
   },
   "source": [
    "Grafiquemos la función de pérdida y los gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EzhH7XZk1N5t"
   },
   "outputs": [],
   "source": [
    "# Gráfica de la curva de aprendizaje (con costes)\n",
    "costes = np.squeeze(d['Costes'])\n",
    "plt.plot(costes)\n",
    "plt.ylabel('coste')\n",
    "plt.xlabel('iteraciones (en cientos)')\n",
    "plt.title(\"Tasa de aprendizaje =\" + str(d[\"Tasa de aprendizaje\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfZW7K0R1N5v"
   },
   "source": [
    "**Interpretación**:\n",
    "Se puede ver el coste decreciendo, demostrando que los parámetros están siendo aprendidos. Sin embargo, el modelo se podría entrenar aun más sobre el conjunto de entrenamiento. Intente aumentar el número de iteraciones arriba y vuelva a ejecutar el código. Podrá ver precisión del conjunto de entrnamiento aumenta, pero la del conjunto de prueba decrece. Este es evidencia del sobre-ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUmPK7ny1N5w"
   },
   "source": [
    "## 6 - Profundizando en el análisis ##\n",
    "\n",
    "Ya tienes un primer modelo de clasificación de imagenes. Analizémoslo un poco más, como por ejemplo examinando distintos valores para la tasa de aprendizaje $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYIe-KzJ1N5x"
   },
   "source": [
    "#### Selección de la tasa de aprendizaje ####\n",
    "\n",
    "**Nota**:\n",
    "Para que el método del GD funcione de manera adecuada, se debe elegir la tasa de aprendiazaje de manera acertada. Esta tasa $\\alpha$  determina qué tan rápido se actualizan los parámetros. Si la tasa es muy grande se puede \"sobrepasar\" el valor óptimo. Y de manera similar, si es muy pequeña se van a necesitar muchas iteraciones para converger a los mejores valores. Por ello la importancia de tener una tase de aprensizaje bien afinada.  \n",
    "\n",
    "Ahora, comparemos la curva de aprendizaje de nuestro modelo con distintas elecciones para $\\alpha$. Ejecute el código abajo. También puede intentar con valores distintos a los tres que estamos utilizando abajo para `learning_rates` y analize los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GytbgP431N5y"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"La tasa de aprendizaje es: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"Costes\"]), label= str(models[str(i)][\"Tasa de aprendizaje\"]))\n",
    "\n",
    "plt.ylabel('coste')\n",
    "plt.xlabel('iteraciones (en cientos)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAwnvlYI1N52"
   },
   "source": [
    "**Discusión**: \n",
    "- Tasas diferentes obtienen costes diferentes y por lo tanto, predicciones diferentes.\n",
    "- Si la tasa es muy grande (0.01), el coste puede oscilar arriba y abajo. Hasta puede diverger, aunque en este ejemplo $\\alpha=0.01$ aun consigue un buen valor para el coste.  \n",
    "- Un coste más bajo no implica un mejor modelo. Se debe chequear si hay una posibilidad de sobre-ajuste. Esto ocurre cuando la precisión de entrenamiento es mucho mayor que la precisión de prueba.\n",
    "- En deep learning, es recomendable que se elija la tasa de aprendizaje que minimize la función de coste. Y si el modelo sobre-ajusta, se pueden probar otras técnicas (que veremos más adelante) para reducir dicho sobre-ajuste. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgS8EChN1N53"
   },
   "source": [
    "## 7 - Pruebe con otras imagenes ##\n",
    "\n",
    "Puede utilizar imagenes propias para ver los resultados de su modelo. Para ello, agregue su(s) imagen(es) al directorio de este cuaderno en la carpeta \"images\", cambie el nombre de la(s) imagen(es) en el siguiente código, y compruebe si el algoritmo acierta (1=gato, 0=no-gato). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wM5hsixV1N53",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### EMPIEZE EL CÓDIGO AQUÍ ### (INTRODUZCA EL NOMBRE DE SU IMAGEN) \n",
    "my_image = \" \"   # el nombre debe coincidir con el de su imagen\n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# Pre-procesamos la imagen\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(int(np.squeeze(my_predicted_image))) + \", el algoritmo predice que es una imagen de un \\\"\" + clases[int(np.squeeze(my_predicted_image))]+  \"\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxBieazi1N57"
   },
   "source": [
    "Ahora puede intentar desarrollar su propio código modificado y compara los resultados. Intente mejorar los resultados obtenidos. Puede jugar con la tasa de aprendizaje, el número de iteraciones o distintos métodos de inicialización. También puede probar otras técnicas de pre-procesamiento, como el de estandarizar los datos, etc. \n",
    "\n",
    "<font color='blue'>\n",
    "**Comentarios finales:**\n",
    "1. Recuerde la importancia del pre-procesamiento de los datos.\n",
    "2. Hemos implementado cada función de manera separada: initialize(), propagate(), optimize(). Y luego se construye el modelo: model().\n",
    "3. La selección adecuada de la tasa de aprendizaje, al cual nos referimos como un \"hiper-parámetro\", puede hacer una gran diferencia en el algoritmo. Seguiremos viendo más ejemplos de esto en actividades futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Cg4OIQt1N58"
   },
   "source": [
    "Algunas referencias:\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Taller2_RegresionLogistica Vacio.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
